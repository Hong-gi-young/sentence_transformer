import pandas as pd
from sentence_transformers import SentenceTransformer, util
import re
import torch

def cleanData(documents):
    # #í•œê¸€ ë° ë„ì–´ì“°ê¸°ë§Œ ë‚¨ê¸°ê³  ì œê±°
    document = re.sub('[^ ê°€-í£]+',"",str(documents))
             
    #íŠ¹ìˆ˜ë¬¸ì ì œê±°
    # document = re.sub('[â˜…â—†â—â–¶â™¥ğŸ±â™»â–³â™¡å† â˜ğŸ¦ºâ—â—†@#$-=+,#/\:^$.@*\"â€»&%ã†ã€\\â€˜|\(\)\[\]\<\>`\'â€¦ã€‹;:â†‘â†’â€˜â€™]',"",document)  
    
    return document
# jhgan/ko-sroberta-multitask
model = SentenceTransformer('jhgan/ko-sroberta-multitask')

df = pd.read_csv('./testing_csv_raw.csv')[['number','string']]

# ìƒˆë¡œìš´ ë¬¸ì¥ ì…ë ¥
query = 'í”¼ë¶€ê°€ ë’¤ì§‘ì–´ì¡Œì–´ìš” ê°œì‹«ì–´ìš” ë¹„ì¶”ì²œí•©ë‹ˆë‹¤'#input("ë¬¸ì¥ì…ë ¥")

new_embeddings = model.encode(query, convert_to_tensor=True)

#ë¶ˆëŸ¬ì˜¨ ë°ì´í„°ì˜ text ë¦¬ìŠ¤íŠ¸í™”
original_text = [i.strip() for i in df['string'].apply(lambda x: cleanData(x)) if len(i)>0]

old_embeddings =  model.encode(original_text, convert_to_tensor=True)

#ìœ ì‚¬ë„ ì ìˆ˜
cosine_scores = util.pytorch_cos_sim(new_embeddings, old_embeddings)

# ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ `top_k` ê°œ ë¬¸ì¥ ì¶”ì¶œ
top_results = torch.topk(cosine_scores, k=30)

print(f"ì…ë ¥ ë¬¸ì¥: {query}")
print(f"\n<ì…ë ¥ ë¬¸ì¥ê³¼ ìœ ì‚¬í•œ {30} ê°œì˜ ë¬¸ì¥>\n")

print('top_results[0]',top_results[0])
print('top_results[1]',top_results[1])

for i, (score, idx) in enumerate(zip(top_results[0][0], top_results[1][0])):
    print(f"{i+1}: {original_text[idx]} {'(ìœ ì‚¬ë„: {:.4f})'.format(score)}\n")